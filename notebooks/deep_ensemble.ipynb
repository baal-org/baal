{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Deep ensembles in BaaL\n",
    "\n",
    "Ensemble are one of the easiest form of Bayesian deep learning.\n",
    " The main drawback from this approach is the important amount of computational resources needed to perform it.\n",
    "  In this notebook, we will present BaaL's Ensemble API namely `EnsembleModelWrapper`.\n",
    "\n",
    "\n",
    "This notebook is similar to our notebook on how to do research, we suggest you look at it first if you haven't.\n",
    "\n",
    "#### Additional resources\n",
    "\n",
    "* More info on the inner working of Active Learning Dataset [here](./fundamentals/active-learning.ipynb).\n",
    "* To know more about Bayesian deep learning please see our Literature review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch.backends\n",
    "from torch import optim, nn\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "from torchvision.transforms import transforms\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from baal.active import get_heuristic, ActiveLearningDataset\n",
    "from baal.active.active_loop import ActiveLearningLoop\n",
    "from baal.ensemble import EnsembleModelWrapper\n",
    "\n",
    "def vgg16(num_classes):\n",
    "    model = models.vgg16(pretrained=False, num_classes=num_classes)\n",
    "    weights = load_state_dict_from_url('https://download.pytorch.org/models/vgg16-397923af.pth')\n",
    "    weights = {k: v for k, v in weights.items() if 'classifier.6' not in k}\n",
    "    model.load_state_dict(weights, strict=False)\n",
    "    return model\n",
    "\n",
    "def weights_reset(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, 0, 0.01)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    epoch: int = 15000//256\n",
    "    batch_size: int = 32\n",
    "    initial_pool: int = 512\n",
    "    query_size: int = 100\n",
    "    lr: float = 0.001\n",
    "    heuristic: str = 'bald'\n",
    "    iterations: int = 5 # Set a low number here since each iteration will train a new model.\n",
    "    training_duration: int = 10\n",
    "        \n",
    "\n",
    "def get_datasets(initial_pool):\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.Resize((32, 32)),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.RandomRotation(30),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(3 * [0.5], 3 * [0.5]), ])\n",
    "    test_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(3 * [0.5], 3 * [0.5]),\n",
    "        ]\n",
    "    )\n",
    "    train_ds = datasets.CIFAR10('.', train=True,\n",
    "                                transform=transform, target_transform=None, download=True)\n",
    "    \n",
    "    # In a real application, you will want a validation set here.\n",
    "    test_set = datasets.CIFAR10('.', train=False,\n",
    "                                transform=test_transform, target_transform=None, download=True)\n",
    "    \n",
    "    # Here we set `pool_specifics`, where we set the transform attribute for the pool.\n",
    "    active_set = ActiveLearningDataset(train_ds, pool_specifics={'transform': test_transform})\n",
    "\n",
    "    # We start labeling randomly.\n",
    "    active_set.label_randomly(initial_pool)\n",
    "    return active_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "hyperparams = ExperimentConfig()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "random.seed(1337)\n",
    "torch.manual_seed(1337)\n",
    "if not use_cuda:\n",
    "    print(\"warning, the experiments would take ages to run on cpu\")\n",
    "\n",
    "# Get datasets\n",
    "active_set, test_set = get_datasets(hyperparams.initial_pool)\n",
    "\n",
    "heuristic = get_heuristic(hyperparams.heuristic)\n",
    "criterion = CrossEntropyLoss()\n",
    "model = vgg16(num_classes=10)\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=hyperparams.lr, momentum=0.9)\n",
    "\n",
    "# Wraps the model into a usable API.\n",
    "model = EnsembleModelWrapper(model, criterion)\n",
    "\n",
    "# for prediction we use a smaller batchsize\n",
    "# since it is slower\n",
    "active_loop = ActiveLearningLoop(active_set,\n",
    "                                 model.predict_on_dataset,\n",
    "                                 heuristic,\n",
    "                                 hyperparams.query_size,\n",
    "                                 batch_size=1,\n",
    "                                 iterations=hyperparams.iterations,\n",
    "                                 use_cuda=use_cuda)\n",
    "\n",
    "# We will reset the weights at each active learning step.\n",
    "init_weights = deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Presenting EnsembleModelWrapper\n",
    "\n",
    "EnsembleModelWrapper is similar to ModelWrapper, but instead of training a single model, we will train multiple.\n",
    "Each model will start its training from a different set parameters.\n",
    "\n",
    "EnsembleModelWrappe methods:\n",
    "\n",
    "```python\n",
    "class EnsembleModelWrapper:\n",
    "    def add_checkpoint(self):\n",
    "        \"\"\"\n",
    "        Add a checkpoint to the list of weights used for inference.\n",
    "        \"\"\"\n",
    "\n",
    "    def clear_checkpoints(self):\n",
    "        \"\"\"\n",
    "        Clear the list of saved checkpoints.\n",
    "        \"\"\"\n",
    "```\n",
    "\n",
    "As you see in the next cell, we call both of these methods alternatively.\n",
    "We train N models, calling `add_checkpoint`, perform the active learning step and then restart by calling `clear_checkpoints`.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38ce1d7eb72483c9a39b960deb6a77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=58.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T18:32:14.935280Z [\u001B[32minfo     ] Starting training              dataset=512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T18:32:24.107167Z [\u001B[32minfo     ] Training complete              train_loss=0.8309454321861267\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T18:32:24.120508Z [\u001B[32minfo     ] Starting training              dataset=512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T18:32:33.379634Z [\u001B[32minfo     ] Training complete              train_loss=0.7256895303726196\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T18:32:33.391207Z [\u001B[32minfo     ] Starting training              dataset=512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T18:32:42.551919Z [\u001B[32minfo     ] Training complete              train_loss=0.7018489241600037\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T18:32:42.564835Z [\u001B[32minfo     ] Starting training              dataset=512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T18:32:51.790118Z [\u001B[32minfo     ] Training complete              train_loss=0.8189429640769958\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T18:32:51.800925Z [\u001B[32minfo     ] Starting training              dataset=512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T18:33:00.990599Z [\u001B[32minfo     ] Training complete              train_loss=0.7541761994361877\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-17T18:33:00.999843Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-17T18:33:16.650087Z [\u001B[32minfo     ] Evaluation complete            test_loss=1.1351398229599\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-17T18:33:16.660014Z [\u001B[32minfo     ] Start Predict                  dataset=49488\n",
      "100%|██████████| 49488/49488 [28:31<00:00, 28.91it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T19:01:48.569941Z [\u001B[32minfo     ] Starting training              dataset=612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T19:01:59.872605Z [\u001B[32minfo     ] Training complete              train_loss=1.0120365619659424\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T19:01:59.882896Z [\u001B[32minfo     ] Starting training              dataset=612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T19:02:11.498706Z [\u001B[32minfo     ] Training complete              train_loss=0.7712851166725159\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T19:02:11.511509Z [\u001B[32minfo     ] Starting training              dataset=612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T19:02:23.104451Z [\u001B[32minfo     ] Training complete              train_loss=0.8971880078315735\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T19:02:23.117584Z [\u001B[32minfo     ] Starting training              dataset=612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T19:02:34.693223Z [\u001B[32minfo     ] Training complete              train_loss=0.783637523651123\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T19:02:34.706303Z [\u001B[32minfo     ] Starting training              dataset=612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T19:02:46.258610Z [\u001B[32minfo     ] Training complete              train_loss=0.8707596063613892\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-17T19:02:46.268248Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-17T19:03:02.003773Z [\u001B[32minfo     ] Evaluation complete            test_loss=1.0180296897888184\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-17T19:03:02.012789Z [\u001B[32minfo     ] Start Predict                  dataset=49388\n",
      "100%|██████████| 49388/49388 [28:28<00:00, 28.90it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T19:31:31.215810Z [\u001B[32minfo     ] Starting training              dataset=712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T19:31:43.243596Z [\u001B[32minfo     ] Training complete              train_loss=0.9962916970252991\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T19:31:43.259154Z [\u001B[32minfo     ] Starting training              dataset=712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T19:31:54.868828Z [\u001B[32minfo     ] Training complete              train_loss=0.8320833444595337\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T19:31:54.879418Z [\u001B[32minfo     ] Starting training              dataset=712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T19:32:06.409709Z [\u001B[32minfo     ] Training complete              train_loss=0.8701471090316772\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T19:32:06.424473Z [\u001B[32minfo     ] Starting training              dataset=712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T19:32:17.989244Z [\u001B[32minfo     ] Training complete              train_loss=1.013999581336975\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T19:32:18.001885Z [\u001B[32minfo     ] Starting training              dataset=712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T19:32:29.661812Z [\u001B[32minfo     ] Training complete              train_loss=0.8868564963340759\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-17T19:32:29.669986Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-17T19:32:45.268449Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.9932419657707214\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-17T19:32:45.277235Z [\u001B[32minfo     ] Start Predict                  dataset=49288\n",
      "100%|██████████| 49288/49288 [28:25<00:00, 28.91it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T20:01:10.741629Z [\u001B[32minfo     ] Starting training              dataset=812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T20:01:23.662742Z [\u001B[32minfo     ] Training complete              train_loss=0.9628363251686096\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T20:01:23.674840Z [\u001B[32minfo     ] Starting training              dataset=812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T20:01:36.365218Z [\u001B[32minfo     ] Training complete              train_loss=0.9962257742881775\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T20:01:36.377082Z [\u001B[32minfo     ] Starting training              dataset=812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T20:01:48.984839Z [\u001B[32minfo     ] Training complete              train_loss=0.9108078479766846\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T20:01:48.997387Z [\u001B[32minfo     ] Starting training              dataset=812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T20:02:01.618966Z [\u001B[32minfo     ] Training complete              train_loss=0.8718828558921814\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T20:02:01.631639Z [\u001B[32minfo     ] Starting training              dataset=812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T20:02:14.209024Z [\u001B[32minfo     ] Training complete              train_loss=0.8640270829200745\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-17T20:02:14.219314Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-17T20:02:29.783429Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.9643571376800537\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-17T20:02:29.793622Z [\u001B[32minfo     ] Start Predict                  dataset=49188\n",
      "100%|██████████| 49188/49188 [28:21<00:00, 28.91it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T20:30:51.412860Z [\u001B[32minfo     ] Starting training              dataset=912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T20:31:05.234635Z [\u001B[32minfo     ] Training complete              train_loss=0.9543710350990295\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T20:31:05.245958Z [\u001B[32minfo     ] Starting training              dataset=912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T20:31:18.885283Z [\u001B[32minfo     ] Training complete              train_loss=0.8887086510658264\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T20:31:18.898161Z [\u001B[32minfo     ] Starting training              dataset=912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T20:31:32.585869Z [\u001B[32minfo     ] Training complete              train_loss=0.8941221833229065\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T20:31:32.600019Z [\u001B[32minfo     ] Starting training              dataset=912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T20:31:46.389338Z [\u001B[32minfo     ] Training complete              train_loss=0.7851525545120239\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T20:31:46.402074Z [\u001B[32minfo     ] Starting training              dataset=912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T20:32:00.163399Z [\u001B[32minfo     ] Training complete              train_loss=1.0442267656326294\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-17T20:32:00.172148Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-17T20:32:15.759007Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.9061288237571716\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-17T20:32:15.768260Z [\u001B[32minfo     ] Start Predict                  dataset=49088\n",
      "100%|██████████| 49088/49088 [28:17<00:00, 28.92it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T21:00:33.795888Z [\u001B[32minfo     ] Starting training              dataset=1012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T21:00:48.837308Z [\u001B[32minfo     ] Training complete              train_loss=0.9000768065452576\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T21:00:48.849308Z [\u001B[32minfo     ] Starting training              dataset=1012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T21:01:03.563037Z [\u001B[32minfo     ] Training complete              train_loss=0.9360002279281616\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T21:01:03.573696Z [\u001B[32minfo     ] Starting training              dataset=1012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T21:01:18.247493Z [\u001B[32minfo     ] Training complete              train_loss=0.9279900193214417\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T21:01:18.259832Z [\u001B[32minfo     ] Starting training              dataset=1012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T21:01:32.942042Z [\u001B[32minfo     ] Training complete              train_loss=0.9436218738555908\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T21:01:32.954055Z [\u001B[32minfo     ] Starting training              dataset=1012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T21:01:47.651501Z [\u001B[32minfo     ] Training complete              train_loss=0.9829102754592896\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-17T21:01:47.660674Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-17T21:02:03.236763Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.8334788084030151\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-17T21:02:03.247166Z [\u001B[32minfo     ] Start Predict                  dataset=48988\n",
      "100%|██████████| 48988/48988 [28:14<00:00, 28.91it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T21:30:17.960207Z [\u001B[32minfo     ] Starting training              dataset=1112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T21:30:34.095634Z [\u001B[32minfo     ] Training complete              train_loss=0.9741942286491394\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T21:30:34.116021Z [\u001B[32minfo     ] Starting training              dataset=1112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T21:30:49.933187Z [\u001B[32minfo     ] Training complete              train_loss=0.877885639667511\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T21:30:49.944921Z [\u001B[32minfo     ] Starting training              dataset=1112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T21:31:05.774312Z [\u001B[32minfo     ] Training complete              train_loss=0.9390765428543091\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T21:31:05.787227Z [\u001B[32minfo     ] Starting training              dataset=1112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T21:31:21.482394Z [\u001B[32minfo     ] Training complete              train_loss=0.9437138438224792\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T21:31:21.495340Z [\u001B[32minfo     ] Starting training              dataset=1112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T21:31:37.232246Z [\u001B[32minfo     ] Training complete              train_loss=0.9867836236953735\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-17T21:31:37.242955Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-17T21:31:52.870279Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.8320015072822571\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-17T21:31:52.879297Z [\u001B[32minfo     ] Start Predict                  dataset=48888\n",
      "100%|██████████| 48888/48888 [28:11<00:00, 28.90it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T22:00:05.165861Z [\u001B[32minfo     ] Starting training              dataset=1212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T22:00:22.366763Z [\u001B[32minfo     ] Training complete              train_loss=0.819810688495636\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T22:00:22.379336Z [\u001B[32minfo     ] Starting training              dataset=1212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T22:00:39.209013Z [\u001B[32minfo     ] Training complete              train_loss=0.9320612549781799\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T22:00:39.219281Z [\u001B[32minfo     ] Starting training              dataset=1212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T22:00:56.026784Z [\u001B[32minfo     ] Training complete              train_loss=0.935141921043396\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T22:00:56.040140Z [\u001B[32minfo     ] Starting training              dataset=1212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T22:01:12.825855Z [\u001B[32minfo     ] Training complete              train_loss=0.9949415326118469\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T22:01:12.840246Z [\u001B[32minfo     ] Starting training              dataset=1212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T22:01:29.617568Z [\u001B[32minfo     ] Training complete              train_loss=0.9300908446311951\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-17T22:01:29.626617Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-17T22:01:45.200478Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.8315033912658691\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-17T22:01:45.213880Z [\u001B[32minfo     ] Start Predict                  dataset=48788\n",
      "100%|██████████| 48788/48788 [28:09<00:00, 28.87it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T22:29:55.385625Z [\u001B[32minfo     ] Starting training              dataset=1312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T22:30:13.178751Z [\u001B[32minfo     ] Training complete              train_loss=1.000781774520874\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T22:30:13.189151Z [\u001B[32minfo     ] Starting training              dataset=1312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T22:30:31.071296Z [\u001B[32minfo     ] Training complete              train_loss=0.9223515391349792\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T22:30:31.081505Z [\u001B[32minfo     ] Starting training              dataset=1312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T22:30:48.828044Z [\u001B[32minfo     ] Training complete              train_loss=0.967280387878418\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T22:30:48.840361Z [\u001B[32minfo     ] Starting training              dataset=1312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T22:31:06.708794Z [\u001B[32minfo     ] Training complete              train_loss=0.9287216663360596\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T22:31:06.721665Z [\u001B[32minfo     ] Starting training              dataset=1312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T22:31:24.499234Z [\u001B[32minfo     ] Training complete              train_loss=0.9399527311325073\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-17T22:31:24.508396Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-17T22:31:40.092260Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.8450648784637451\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-17T22:31:40.102699Z [\u001B[32minfo     ] Start Predict                  dataset=48688\n",
      "100%|██████████| 48688/48688 [28:05<00:00, 28.88it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T22:59:46.252859Z [\u001B[32minfo     ] Starting training              dataset=1412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T23:00:05.472228Z [\u001B[32minfo     ] Training complete              train_loss=0.9970430731773376\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T23:00:05.484009Z [\u001B[32minfo     ] Starting training              dataset=1412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T23:00:24.729219Z [\u001B[32minfo     ] Training complete              train_loss=1.0275945663452148\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T23:00:24.742010Z [\u001B[32minfo     ] Starting training              dataset=1412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T23:00:44.053153Z [\u001B[32minfo     ] Training complete              train_loss=0.9986000061035156\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T23:00:44.066443Z [\u001B[32minfo     ] Starting training              dataset=1412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T23:01:03.387000Z [\u001B[32minfo     ] Training complete              train_loss=0.9493470788002014\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T23:01:03.398905Z [\u001B[32minfo     ] Starting training              dataset=1412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T23:01:22.786546Z [\u001B[32minfo     ] Training complete              train_loss=0.9630196690559387\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-17T23:01:22.796536Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-17T23:01:38.413688Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.7981237173080444\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-17T23:01:38.423405Z [\u001B[32minfo     ] Start Predict                  dataset=48588\n",
      "100%|██████████| 48588/48588 [28:03<00:00, 28.86it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T23:29:42.423745Z [\u001B[32minfo     ] Starting training              dataset=1512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T23:30:02.696849Z [\u001B[32minfo     ] Training complete              train_loss=0.9856109619140625\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T23:30:02.709133Z [\u001B[32minfo     ] Starting training              dataset=1512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T23:30:22.955740Z [\u001B[32minfo     ] Training complete              train_loss=1.0540472269058228\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T23:30:22.968199Z [\u001B[32minfo     ] Starting training              dataset=1512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T23:30:43.252147Z [\u001B[32minfo     ] Training complete              train_loss=0.9176915287971497\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T23:30:43.265019Z [\u001B[32minfo     ] Starting training              dataset=1512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T23:31:03.538857Z [\u001B[32minfo     ] Training complete              train_loss=1.0027012825012207\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T23:31:03.551033Z [\u001B[32minfo     ] Starting training              dataset=1512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-17T23:31:23.912405Z [\u001B[32minfo     ] Training complete              train_loss=0.9596385955810547\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-17T23:31:23.921660Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-17T23:31:39.511722Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.8183822631835938\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-17T23:31:39.521293Z [\u001B[32minfo     ] Start Predict                  dataset=48488\n",
      "100%|██████████| 48488/48488 [27:59<00:00, 28.87it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-17T23:59:39.667940Z [\u001B[32minfo     ] Starting training              dataset=1612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T00:00:01.066558Z [\u001B[32minfo     ] Training complete              train_loss=1.0180639028549194\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T00:00:01.078217Z [\u001B[32minfo     ] Starting training              dataset=1612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T00:00:22.499226Z [\u001B[32minfo     ] Training complete              train_loss=0.8685591220855713\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T00:00:22.512176Z [\u001B[32minfo     ] Starting training              dataset=1612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T00:00:43.834675Z [\u001B[32minfo     ] Training complete              train_loss=0.9837992191314697\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T00:00:43.846805Z [\u001B[32minfo     ] Starting training              dataset=1612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T00:01:05.277094Z [\u001B[32minfo     ] Training complete              train_loss=0.8587186932563782\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T00:01:05.289982Z [\u001B[32minfo     ] Starting training              dataset=1612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T00:01:26.666700Z [\u001B[32minfo     ] Training complete              train_loss=0.9525586366653442\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T00:01:26.676016Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T00:01:42.267987Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.7479233145713806\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T00:01:42.277480Z [\u001B[32minfo     ] Start Predict                  dataset=48388\n",
      "100%|██████████| 48388/48388 [27:56<00:00, 28.86it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T00:29:39.363901Z [\u001B[32minfo     ] Starting training              dataset=1712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T00:30:01.708274Z [\u001B[32minfo     ] Training complete              train_loss=0.9032265543937683\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T00:30:01.720112Z [\u001B[32minfo     ] Starting training              dataset=1712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T00:30:24.128646Z [\u001B[32minfo     ] Training complete              train_loss=0.9958771467208862\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T00:30:24.141564Z [\u001B[32minfo     ] Starting training              dataset=1712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T00:30:46.455215Z [\u001B[32minfo     ] Training complete              train_loss=0.9266777038574219\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T00:30:46.467605Z [\u001B[32minfo     ] Starting training              dataset=1712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T00:31:08.745332Z [\u001B[32minfo     ] Training complete              train_loss=0.9749760031700134\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T00:31:08.756904Z [\u001B[32minfo     ] Starting training              dataset=1712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T00:31:31.142031Z [\u001B[32minfo     ] Training complete              train_loss=0.9794679284095764\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T00:31:31.151633Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T00:31:46.772870Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.7474648952484131\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T00:31:46.782521Z [\u001B[32minfo     ] Start Predict                  dataset=48288\n",
      "100%|██████████| 48288/48288 [27:51<00:00, 28.89it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T00:59:38.760135Z [\u001B[32minfo     ] Starting training              dataset=1812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T01:00:02.277678Z [\u001B[32minfo     ] Training complete              train_loss=0.9012413620948792\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T01:00:02.291061Z [\u001B[32minfo     ] Starting training              dataset=1812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T01:00:25.677069Z [\u001B[32minfo     ] Training complete              train_loss=0.9153404235839844\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T01:00:25.688802Z [\u001B[32minfo     ] Starting training              dataset=1812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T01:00:49.133905Z [\u001B[32minfo     ] Training complete              train_loss=0.9643362760543823\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T01:00:49.149654Z [\u001B[32minfo     ] Starting training              dataset=1812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T01:01:12.516117Z [\u001B[32minfo     ] Training complete              train_loss=0.942247748374939\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T01:01:12.528021Z [\u001B[32minfo     ] Starting training              dataset=1812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T01:01:36.036944Z [\u001B[32minfo     ] Training complete              train_loss=1.0193837881088257\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T01:01:36.046469Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T01:01:51.637669Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.7428709268569946\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T01:01:51.647215Z [\u001B[32minfo     ] Start Predict                  dataset=48188\n",
      "100%|██████████| 48188/48188 [27:47<00:00, 28.89it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T01:29:39.822019Z [\u001B[32minfo     ] Starting training              dataset=1912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T01:30:04.302267Z [\u001B[32minfo     ] Training complete              train_loss=0.9798358678817749\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T01:30:04.314605Z [\u001B[32minfo     ] Starting training              dataset=1912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T01:30:28.748361Z [\u001B[32minfo     ] Training complete              train_loss=0.9685439467430115\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T01:30:28.760838Z [\u001B[32minfo     ] Starting training              dataset=1912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T01:30:53.252081Z [\u001B[32minfo     ] Training complete              train_loss=0.9249350428581238\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T01:30:53.263317Z [\u001B[32minfo     ] Starting training              dataset=1912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T01:31:17.658173Z [\u001B[32minfo     ] Training complete              train_loss=1.0120034217834473\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T01:31:17.673308Z [\u001B[32minfo     ] Starting training              dataset=1912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T01:31:42.138920Z [\u001B[32minfo     ] Training complete              train_loss=0.9617471098899841\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T01:31:42.150255Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T01:31:57.755324Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.7146279811859131\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T01:31:57.767610Z [\u001B[32minfo     ] Start Predict                  dataset=48088\n",
      "100%|██████████| 48088/48088 [27:45<00:00, 28.87it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T01:59:43.962947Z [\u001B[32minfo     ] Starting training              dataset=2012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T02:00:09.383701Z [\u001B[32minfo     ] Training complete              train_loss=0.9600884318351746\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T02:00:09.393117Z [\u001B[32minfo     ] Starting training              dataset=2012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T02:00:34.897472Z [\u001B[32minfo     ] Training complete              train_loss=1.0028831958770752\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T02:00:34.911210Z [\u001B[32minfo     ] Starting training              dataset=2012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T02:01:00.501471Z [\u001B[32minfo     ] Training complete              train_loss=0.9784283638000488\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T02:01:00.513346Z [\u001B[32minfo     ] Starting training              dataset=2012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T02:01:25.937907Z [\u001B[32minfo     ] Training complete              train_loss=0.8830503821372986\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T02:01:25.951978Z [\u001B[32minfo     ] Starting training              dataset=2012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T02:01:51.564100Z [\u001B[32minfo     ] Training complete              train_loss=0.9322289228439331\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T02:01:51.572518Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T02:02:07.146975Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.7225781679153442\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T02:02:07.156886Z [\u001B[32minfo     ] Start Predict                  dataset=47988\n",
      "100%|██████████| 47988/47988 [27:42<00:00, 28.87it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T02:29:49.839890Z [\u001B[32minfo     ] Starting training              dataset=2112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T02:30:16.304875Z [\u001B[32minfo     ] Training complete              train_loss=1.0111409425735474\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T02:30:16.317184Z [\u001B[32minfo     ] Starting training              dataset=2112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T02:30:42.898292Z [\u001B[32minfo     ] Training complete              train_loss=1.0319634675979614\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T02:30:42.910571Z [\u001B[32minfo     ] Starting training              dataset=2112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T02:31:09.425868Z [\u001B[32minfo     ] Training complete              train_loss=0.9712992310523987\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T02:31:09.435156Z [\u001B[32minfo     ] Starting training              dataset=2112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T02:31:36.004948Z [\u001B[32minfo     ] Training complete              train_loss=0.9338739514350891\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T02:31:36.016208Z [\u001B[32minfo     ] Starting training              dataset=2112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T02:32:02.473132Z [\u001B[32minfo     ] Training complete              train_loss=0.9131288528442383\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T02:32:02.482465Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T02:32:18.070596Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.7218673229217529\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T02:32:18.080041Z [\u001B[32minfo     ] Start Predict                  dataset=47888\n",
      "100%|██████████| 47888/47888 [27:41<00:00, 28.82it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T03:00:00.249232Z [\u001B[32minfo     ] Starting training              dataset=2212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T03:00:28.243536Z [\u001B[32minfo     ] Training complete              train_loss=1.0218558311462402\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T03:00:28.255499Z [\u001B[32minfo     ] Starting training              dataset=2212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T03:00:56.306050Z [\u001B[32minfo     ] Training complete              train_loss=1.0099849700927734\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T03:00:56.318845Z [\u001B[32minfo     ] Starting training              dataset=2212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T03:01:24.307997Z [\u001B[32minfo     ] Training complete              train_loss=1.0540506839752197\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T03:01:24.318188Z [\u001B[32minfo     ] Starting training              dataset=2212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T03:01:52.314654Z [\u001B[32minfo     ] Training complete              train_loss=1.092423439025879\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T03:01:52.325948Z [\u001B[32minfo     ] Starting training              dataset=2212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T03:02:20.274720Z [\u001B[32minfo     ] Training complete              train_loss=0.9491524696350098\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T03:02:20.284116Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T03:02:35.898981Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.7051872611045837\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T03:02:35.908670Z [\u001B[32minfo     ] Start Predict                  dataset=47788\n",
      "100%|██████████| 47788/47788 [27:39<00:00, 28.80it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T03:30:15.707423Z [\u001B[32minfo     ] Starting training              dataset=2312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T03:30:44.674477Z [\u001B[32minfo     ] Training complete              train_loss=1.0274678468704224\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T03:30:44.686497Z [\u001B[32minfo     ] Starting training              dataset=2312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T03:31:13.866785Z [\u001B[32minfo     ] Training complete              train_loss=0.968182384967804\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T03:31:13.880672Z [\u001B[32minfo     ] Starting training              dataset=2312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T03:31:43.019192Z [\u001B[32minfo     ] Training complete              train_loss=0.9426356554031372\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T03:31:43.028229Z [\u001B[32minfo     ] Starting training              dataset=2312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T03:32:12.057223Z [\u001B[32minfo     ] Training complete              train_loss=0.9900460243225098\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T03:32:12.070905Z [\u001B[32minfo     ] Starting training              dataset=2312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T03:32:40.975337Z [\u001B[32minfo     ] Training complete              train_loss=1.051175832748413\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T03:32:40.982938Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T03:32:56.591519Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.6920835971832275\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T03:32:56.600992Z [\u001B[32minfo     ] Start Predict                  dataset=47688\n",
      "100%|██████████| 47688/47688 [27:35<00:00, 28.81it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T04:00:32.136144Z [\u001B[32minfo     ] Starting training              dataset=2412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T04:01:02.273580Z [\u001B[32minfo     ] Training complete              train_loss=0.949519693851471\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T04:01:02.286346Z [\u001B[32minfo     ] Starting training              dataset=2412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T04:01:32.335692Z [\u001B[32minfo     ] Training complete              train_loss=1.0025725364685059\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T04:01:32.346785Z [\u001B[32minfo     ] Starting training              dataset=2412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T04:02:02.420534Z [\u001B[32minfo     ] Training complete              train_loss=0.9575701355934143\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T04:02:02.435137Z [\u001B[32minfo     ] Starting training              dataset=2412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T04:02:32.506009Z [\u001B[32minfo     ] Training complete              train_loss=0.9230617880821228\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T04:02:32.517621Z [\u001B[32minfo     ] Starting training              dataset=2412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T04:03:02.579687Z [\u001B[32minfo     ] Training complete              train_loss=0.9486559629440308\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T04:03:02.589148Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T04:03:18.190767Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.6648305654525757\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T04:03:18.198617Z [\u001B[32minfo     ] Start Predict                  dataset=47588\n",
      "100%|██████████| 47588/47588 [27:31<00:00, 28.82it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T04:30:49.735046Z [\u001B[32minfo     ] Starting training              dataset=2512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T04:31:20.963962Z [\u001B[32minfo     ] Training complete              train_loss=0.9411851763725281\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T04:31:20.976653Z [\u001B[32minfo     ] Starting training              dataset=2512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T04:31:51.951719Z [\u001B[32minfo     ] Training complete              train_loss=0.9108667373657227\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T04:31:51.964309Z [\u001B[32minfo     ] Starting training              dataset=2512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T04:32:22.967182Z [\u001B[32minfo     ] Training complete              train_loss=0.9474301934242249\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T04:32:22.979044Z [\u001B[32minfo     ] Starting training              dataset=2512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T04:32:54.027079Z [\u001B[32minfo     ] Training complete              train_loss=0.9340396523475647\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T04:32:54.039232Z [\u001B[32minfo     ] Starting training              dataset=2512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T04:33:25.099795Z [\u001B[32minfo     ] Training complete              train_loss=1.047899603843689\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T04:33:25.107887Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T04:33:40.700554Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.6528348326683044\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T04:33:40.710438Z [\u001B[32minfo     ] Start Predict                  dataset=47488\n",
      "100%|██████████| 47488/47488 [27:27<00:00, 28.83it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T05:01:08.232367Z [\u001B[32minfo     ] Starting training              dataset=2612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T05:01:40.305516Z [\u001B[32minfo     ] Training complete              train_loss=0.9628450274467468\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T05:01:40.317440Z [\u001B[32minfo     ] Starting training              dataset=2612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T05:02:12.399283Z [\u001B[32minfo     ] Training complete              train_loss=0.9817005395889282\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T05:02:12.412246Z [\u001B[32minfo     ] Starting training              dataset=2612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T05:02:44.473116Z [\u001B[32minfo     ] Training complete              train_loss=0.9636927247047424\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T05:02:44.486364Z [\u001B[32minfo     ] Starting training              dataset=2612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T05:03:16.640770Z [\u001B[32minfo     ] Training complete              train_loss=0.9591647982597351\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T05:03:16.653575Z [\u001B[32minfo     ] Starting training              dataset=2612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T05:03:48.641398Z [\u001B[32minfo     ] Training complete              train_loss=1.0123170614242554\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T05:03:48.648540Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T05:04:04.275825Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.6550676822662354\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T05:04:04.284975Z [\u001B[32minfo     ] Start Predict                  dataset=47388\n",
      "100%|██████████| 47388/47388 [27:26<00:00, 28.79it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T05:31:30.703056Z [\u001B[32minfo     ] Starting training              dataset=2712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T05:32:03.865722Z [\u001B[32minfo     ] Training complete              train_loss=0.9640587568283081\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T05:32:03.876315Z [\u001B[32minfo     ] Starting training              dataset=2712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T05:32:37.128643Z [\u001B[32minfo     ] Training complete              train_loss=0.9650281071662903\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T05:32:37.140762Z [\u001B[32minfo     ] Starting training              dataset=2712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T05:33:10.241204Z [\u001B[32minfo     ] Training complete              train_loss=0.9435812830924988\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T05:33:10.253632Z [\u001B[32minfo     ] Starting training              dataset=2712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T05:33:43.435159Z [\u001B[32minfo     ] Training complete              train_loss=0.9820657968521118\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T05:33:43.448779Z [\u001B[32minfo     ] Starting training              dataset=2712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T05:34:16.500978Z [\u001B[32minfo     ] Training complete              train_loss=0.9420306086540222\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T05:34:16.512458Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T05:34:32.094882Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.6306995749473572\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T05:34:32.106281Z [\u001B[32minfo     ] Start Predict                  dataset=47288\n",
      "100%|██████████| 47288/47288 [27:25<00:00, 28.75it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T06:01:57.509065Z [\u001B[32minfo     ] Starting training              dataset=2812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T06:02:31.731745Z [\u001B[32minfo     ] Training complete              train_loss=0.9453544020652771\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T06:02:31.743338Z [\u001B[32minfo     ] Starting training              dataset=2812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T06:03:06.017337Z [\u001B[32minfo     ] Training complete              train_loss=0.9973684549331665\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T06:03:06.031009Z [\u001B[32minfo     ] Starting training              dataset=2812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T06:03:40.182783Z [\u001B[32minfo     ] Training complete              train_loss=0.9325040578842163\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T06:03:40.197740Z [\u001B[32minfo     ] Starting training              dataset=2812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T06:04:14.358574Z [\u001B[32minfo     ] Training complete              train_loss=1.058993935585022\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T06:04:14.371615Z [\u001B[32minfo     ] Starting training              dataset=2812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T06:04:48.461801Z [\u001B[32minfo     ] Training complete              train_loss=0.9620432257652283\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T06:04:48.469947Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T06:05:04.066278Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.6350358724594116\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T06:05:04.074587Z [\u001B[32minfo     ] Start Predict                  dataset=47188\n",
      "100%|██████████| 47188/47188 [27:20<00:00, 28.76it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T06:32:24.951982Z [\u001B[32minfo     ] Starting training              dataset=2912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T06:33:00.085869Z [\u001B[32minfo     ] Training complete              train_loss=0.9641933441162109\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T06:33:00.097627Z [\u001B[32minfo     ] Starting training              dataset=2912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T06:33:35.380542Z [\u001B[32minfo     ] Training complete              train_loss=0.9780193567276001\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T06:33:35.391866Z [\u001B[32minfo     ] Starting training              dataset=2912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T06:34:10.622811Z [\u001B[32minfo     ] Training complete              train_loss=0.9412575960159302\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T06:34:10.635345Z [\u001B[32minfo     ] Starting training              dataset=2912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T06:34:45.819401Z [\u001B[32minfo     ] Training complete              train_loss=0.9475481510162354\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T06:34:45.832107Z [\u001B[32minfo     ] Starting training              dataset=2912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T06:35:20.992778Z [\u001B[32minfo     ] Training complete              train_loss=0.9300572872161865\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T06:35:21.002776Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T06:35:36.628600Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.6201751232147217\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T06:35:36.638357Z [\u001B[32minfo     ] Start Predict                  dataset=47088\n",
      "100%|██████████| 47088/47088 [27:15<00:00, 28.78it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T07:02:52.916514Z [\u001B[32minfo     ] Starting training              dataset=3012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T07:03:29.462947Z [\u001B[32minfo     ] Training complete              train_loss=0.9466053247451782\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T07:03:29.474459Z [\u001B[32minfo     ] Starting training              dataset=3012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T07:04:06.174960Z [\u001B[32minfo     ] Training complete              train_loss=0.9979209303855896\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T07:04:06.187846Z [\u001B[32minfo     ] Starting training              dataset=3012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T07:04:42.935840Z [\u001B[32minfo     ] Training complete              train_loss=0.9705447554588318\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T07:04:42.947947Z [\u001B[32minfo     ] Starting training              dataset=3012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T07:05:19.666234Z [\u001B[32minfo     ] Training complete              train_loss=1.015205979347229\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T07:05:19.677713Z [\u001B[32minfo     ] Starting training              dataset=3012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T07:05:56.351902Z [\u001B[32minfo     ] Training complete              train_loss=0.9861984848976135\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T07:05:56.360344Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T07:06:11.956501Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.6243948340415955\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T07:06:11.965644Z [\u001B[32minfo     ] Start Predict                  dataset=46988\n",
      "100%|██████████| 46988/46988 [27:13<00:00, 28.76it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T07:33:26.098344Z [\u001B[32minfo     ] Starting training              dataset=3112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T07:34:03.854103Z [\u001B[32minfo     ] Training complete              train_loss=1.0630651712417603\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T07:34:03.866101Z [\u001B[32minfo     ] Starting training              dataset=3112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T07:34:41.644256Z [\u001B[32minfo     ] Training complete              train_loss=1.0335196256637573\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T07:34:41.654892Z [\u001B[32minfo     ] Starting training              dataset=3112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T07:35:19.380822Z [\u001B[32minfo     ] Training complete              train_loss=0.9523045420646667\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T07:35:19.393181Z [\u001B[32minfo     ] Starting training              dataset=3112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T07:35:57.182686Z [\u001B[32minfo     ] Training complete              train_loss=0.9351483583450317\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T07:35:57.196085Z [\u001B[32minfo     ] Starting training              dataset=3112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T07:36:34.980835Z [\u001B[32minfo     ] Training complete              train_loss=0.9676393270492554\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T07:36:34.989513Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T07:36:50.621703Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.618861973285675\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T07:36:50.632689Z [\u001B[32minfo     ] Start Predict                  dataset=46888\n",
      "100%|██████████| 46888/46888 [27:12<00:00, 28.73it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T08:04:03.162328Z [\u001B[32minfo     ] Starting training              dataset=3212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T08:04:41.918042Z [\u001B[32minfo     ] Training complete              train_loss=0.990033745765686\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T08:04:41.930740Z [\u001B[32minfo     ] Starting training              dataset=3212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T08:05:20.809396Z [\u001B[32minfo     ] Training complete              train_loss=0.9560612440109253\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T08:05:20.823029Z [\u001B[32minfo     ] Starting training              dataset=3212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T08:05:59.644789Z [\u001B[32minfo     ] Training complete              train_loss=1.0093096494674683\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T08:05:59.658109Z [\u001B[32minfo     ] Starting training              dataset=3212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T08:06:38.461425Z [\u001B[32minfo     ] Training complete              train_loss=0.9644139409065247\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T08:06:38.475153Z [\u001B[32minfo     ] Starting training              dataset=3212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T08:07:17.166215Z [\u001B[32minfo     ] Training complete              train_loss=0.9002879858016968\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T08:07:17.173031Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T08:07:32.864483Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.6072748899459839\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T08:07:32.873714Z [\u001B[32minfo     ] Start Predict                  dataset=46788\n",
      "100%|██████████| 46788/46788 [27:08<00:00, 28.73it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T08:34:41.804427Z [\u001B[32minfo     ] Starting training              dataset=3312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T08:35:21.583164Z [\u001B[32minfo     ] Training complete              train_loss=0.948034942150116\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T08:35:21.596181Z [\u001B[32minfo     ] Starting training              dataset=3312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T08:36:01.496768Z [\u001B[32minfo     ] Training complete              train_loss=0.944650411605835\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T08:36:01.508441Z [\u001B[32minfo     ] Starting training              dataset=3312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T08:36:41.316889Z [\u001B[32minfo     ] Training complete              train_loss=0.9609594345092773\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T08:36:41.328115Z [\u001B[32minfo     ] Starting training              dataset=3312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T08:37:21.173133Z [\u001B[32minfo     ] Training complete              train_loss=0.9496522545814514\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T08:37:21.188784Z [\u001B[32minfo     ] Starting training              dataset=3312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T08:38:00.958070Z [\u001B[32minfo     ] Training complete              train_loss=0.9714163541793823\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T08:38:00.967359Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T08:38:16.598260Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.5899434685707092\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T08:38:16.608850Z [\u001B[32minfo     ] Start Predict                  dataset=46688\n",
      "100%|██████████| 46688/46688 [27:03<00:00, 28.76it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T09:05:20.453009Z [\u001B[32minfo     ] Starting training              dataset=3412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T09:06:01.331648Z [\u001B[32minfo     ] Training complete              train_loss=0.9535933136940002\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T09:06:01.346175Z [\u001B[32minfo     ] Starting training              dataset=3412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T09:06:42.168222Z [\u001B[32minfo     ] Training complete              train_loss=0.9712793827056885\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T09:06:42.183770Z [\u001B[32minfo     ] Starting training              dataset=3412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T09:07:23.066888Z [\u001B[32minfo     ] Training complete              train_loss=0.9640957117080688\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T09:07:23.077609Z [\u001B[32minfo     ] Starting training              dataset=3412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T09:08:04.039523Z [\u001B[32minfo     ] Training complete              train_loss=0.9819205403327942\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T09:08:04.051080Z [\u001B[32minfo     ] Starting training              dataset=3412 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T09:08:44.810700Z [\u001B[32minfo     ] Training complete              train_loss=0.9889603853225708\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T09:08:44.819587Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T09:09:00.449864Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.5989570617675781\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T09:09:00.465135Z [\u001B[32minfo     ] Start Predict                  dataset=46588\n",
      "100%|██████████| 46588/46588 [27:00<00:00, 28.76it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T09:36:00.856796Z [\u001B[32minfo     ] Starting training              dataset=3512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T09:36:42.771994Z [\u001B[32minfo     ] Training complete              train_loss=0.927920937538147\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T09:36:42.784194Z [\u001B[32minfo     ] Starting training              dataset=3512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T09:37:24.726141Z [\u001B[32minfo     ] Training complete              train_loss=0.9861028790473938\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T09:37:24.737632Z [\u001B[32minfo     ] Starting training              dataset=3512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T09:38:06.830277Z [\u001B[32minfo     ] Training complete              train_loss=1.0070308446884155\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T09:38:06.843702Z [\u001B[32minfo     ] Starting training              dataset=3512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T09:38:48.665344Z [\u001B[32minfo     ] Training complete              train_loss=0.9916149973869324\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T09:38:48.676017Z [\u001B[32minfo     ] Starting training              dataset=3512 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T09:39:30.570858Z [\u001B[32minfo     ] Training complete              train_loss=0.9248360395431519\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T09:39:30.578653Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T09:39:46.190796Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.5978270769119263\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T09:39:46.201326Z [\u001B[32minfo     ] Start Predict                  dataset=46488\n",
      "100%|██████████| 46488/46488 [26:56<00:00, 28.76it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T10:06:43.194063Z [\u001B[32minfo     ] Starting training              dataset=3612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T10:07:26.171669Z [\u001B[32minfo     ] Training complete              train_loss=0.9684633016586304\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T10:07:26.184589Z [\u001B[32minfo     ] Starting training              dataset=3612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T10:08:09.102514Z [\u001B[32minfo     ] Training complete              train_loss=0.9826749563217163\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T10:08:09.116936Z [\u001B[32minfo     ] Starting training              dataset=3612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T10:08:52.011417Z [\u001B[32minfo     ] Training complete              train_loss=0.9363336563110352\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T10:08:52.023803Z [\u001B[32minfo     ] Starting training              dataset=3612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T10:09:34.944114Z [\u001B[32minfo     ] Training complete              train_loss=0.9838319420814514\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T10:09:34.955873Z [\u001B[32minfo     ] Starting training              dataset=3612 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T10:10:17.846679Z [\u001B[32minfo     ] Training complete              train_loss=0.9771363735198975\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T10:10:17.858153Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T10:10:33.470680Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.5789777636528015\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T10:10:33.480112Z [\u001B[32minfo     ] Start Predict                  dataset=46388\n",
      "100%|██████████| 46388/46388 [26:53<00:00, 28.75it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T10:37:27.043119Z [\u001B[32minfo     ] Starting training              dataset=3712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T10:38:11.023107Z [\u001B[32minfo     ] Training complete              train_loss=0.967948853969574\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T10:38:11.036147Z [\u001B[32minfo     ] Starting training              dataset=3712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T10:38:55.059323Z [\u001B[32minfo     ] Training complete              train_loss=0.9402305483818054\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T10:38:55.071628Z [\u001B[32minfo     ] Starting training              dataset=3712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T10:39:39.006696Z [\u001B[32minfo     ] Training complete              train_loss=0.9755014777183533\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T10:39:39.019401Z [\u001B[32minfo     ] Starting training              dataset=3712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T10:40:22.941095Z [\u001B[32minfo     ] Training complete              train_loss=0.949572741985321\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T10:40:22.954065Z [\u001B[32minfo     ] Starting training              dataset=3712 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T10:41:06.889294Z [\u001B[32minfo     ] Training complete              train_loss=0.9363774061203003\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T10:41:06.898086Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T10:41:22.486154Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.5791571140289307\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T10:41:22.498676Z [\u001B[32minfo     ] Start Predict                  dataset=46288\n",
      "100%|██████████| 46288/46288 [26:50<00:00, 28.74it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T11:08:13.590406Z [\u001B[32minfo     ] Starting training              dataset=3812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T11:08:58.943754Z [\u001B[32minfo     ] Training complete              train_loss=0.9444110989570618\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T11:08:58.955274Z [\u001B[32minfo     ] Starting training              dataset=3812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T11:09:44.544927Z [\u001B[32minfo     ] Training complete              train_loss=0.9988128542900085\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T11:09:44.558511Z [\u001B[32minfo     ] Starting training              dataset=3812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T11:10:30.218683Z [\u001B[32minfo     ] Training complete              train_loss=1.0005743503570557\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T11:10:30.229904Z [\u001B[32minfo     ] Starting training              dataset=3812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T11:11:15.784854Z [\u001B[32minfo     ] Training complete              train_loss=0.9297496676445007\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T11:11:15.798939Z [\u001B[32minfo     ] Starting training              dataset=3812 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T11:12:01.283883Z [\u001B[32minfo     ] Training complete              train_loss=0.9709999561309814\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T11:12:01.291329Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T11:12:16.961816Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.5633509755134583\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T11:12:16.970940Z [\u001B[32minfo     ] Start Predict                  dataset=46188\n",
      "100%|██████████| 46188/46188 [26:47<00:00, 28.73it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T11:39:05.218450Z [\u001B[32minfo     ] Starting training              dataset=3912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T11:39:51.702688Z [\u001B[32minfo     ] Training complete              train_loss=0.9808095097541809\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T11:39:51.714369Z [\u001B[32minfo     ] Starting training              dataset=3912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T11:40:38.243699Z [\u001B[32minfo     ] Training complete              train_loss=1.0215200185775757\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T11:40:38.256504Z [\u001B[32minfo     ] Starting training              dataset=3912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T11:41:24.814849Z [\u001B[32minfo     ] Training complete              train_loss=0.9931920170783997\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T11:41:24.825958Z [\u001B[32minfo     ] Starting training              dataset=3912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T11:42:11.434426Z [\u001B[32minfo     ] Training complete              train_loss=0.9641764163970947\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T11:42:11.447582Z [\u001B[32minfo     ] Starting training              dataset=3912 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T11:42:58.072240Z [\u001B[32minfo     ] Training complete              train_loss=0.9970871806144714\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T11:42:58.081615Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T11:43:13.771625Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.5712881684303284\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T11:43:13.782101Z [\u001B[32minfo     ] Start Predict                  dataset=46088\n",
      "100%|██████████| 46088/46088 [26:43<00:00, 28.75it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T12:09:57.420614Z [\u001B[32minfo     ] Starting training              dataset=4012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T12:10:44.838013Z [\u001B[32minfo     ] Training complete              train_loss=0.9467557072639465\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T12:10:44.850626Z [\u001B[32minfo     ] Starting training              dataset=4012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T12:11:32.284071Z [\u001B[32minfo     ] Training complete              train_loss=0.9280139207839966\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T12:11:32.295218Z [\u001B[32minfo     ] Starting training              dataset=4012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T12:12:19.935922Z [\u001B[32minfo     ] Training complete              train_loss=0.9149056077003479\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T12:12:19.947329Z [\u001B[32minfo     ] Starting training              dataset=4012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T12:13:07.355948Z [\u001B[32minfo     ] Training complete              train_loss=0.999696671962738\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T12:13:07.367123Z [\u001B[32minfo     ] Starting training              dataset=4012 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T12:13:54.921567Z [\u001B[32minfo     ] Training complete              train_loss=0.9322537779808044\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T12:13:54.929667Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T12:14:10.606622Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.5577137470245361\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T12:14:10.616797Z [\u001B[32minfo     ] Start Predict                  dataset=45988\n",
      "100%|██████████| 45988/45988 [26:39<00:00, 28.75it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T12:40:50.384904Z [\u001B[32minfo     ] Starting training              dataset=4112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T12:41:39.015498Z [\u001B[32minfo     ] Training complete              train_loss=0.9797711968421936\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T12:41:39.030215Z [\u001B[32minfo     ] Starting training              dataset=4112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T12:42:27.687693Z [\u001B[32minfo     ] Training complete              train_loss=0.9403604865074158\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T12:42:27.700762Z [\u001B[32minfo     ] Starting training              dataset=4112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T12:43:16.229070Z [\u001B[32minfo     ] Training complete              train_loss=0.9262610077857971\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T12:43:16.241272Z [\u001B[32minfo     ] Starting training              dataset=4112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T12:44:04.934801Z [\u001B[32minfo     ] Training complete              train_loss=0.9547136425971985\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T12:44:04.948018Z [\u001B[32minfo     ] Starting training              dataset=4112 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T12:44:53.712009Z [\u001B[32minfo     ] Training complete              train_loss=0.9833473563194275\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T12:44:53.721290Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T12:45:09.337155Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.5600048899650574\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T12:45:09.346021Z [\u001B[32minfo     ] Start Predict                  dataset=45888\n",
      "100%|██████████| 45888/45888 [26:37<00:00, 28.73it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T13:11:46.855027Z [\u001B[32minfo     ] Starting training              dataset=4212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T13:12:36.430103Z [\u001B[32minfo     ] Training complete              train_loss=0.9595631957054138\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T13:12:36.442591Z [\u001B[32minfo     ] Starting training              dataset=4212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T13:13:26.079943Z [\u001B[32minfo     ] Training complete              train_loss=0.9271482229232788\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T13:13:26.093282Z [\u001B[32minfo     ] Starting training              dataset=4212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T13:14:15.887292Z [\u001B[32minfo     ] Training complete              train_loss=1.0371108055114746\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T13:14:15.900355Z [\u001B[32minfo     ] Starting training              dataset=4212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T13:15:05.676284Z [\u001B[32minfo     ] Training complete              train_loss=0.9792743921279907\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T13:15:05.687454Z [\u001B[32minfo     ] Starting training              dataset=4212 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T13:15:55.384134Z [\u001B[32minfo     ] Training complete              train_loss=0.9417975544929504\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T13:15:55.392922Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T13:16:11.000616Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.5502018332481384\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T13:16:11.012342Z [\u001B[32minfo     ] Start Predict                  dataset=45788\n",
      "100%|██████████| 45788/45788 [26:32<00:00, 28.76it/s]\n",
      "Training model 0\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T13:42:43.519555Z [\u001B[32minfo     ] Starting training              dataset=4312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T13:43:34.291217Z [\u001B[32minfo     ] Training complete              train_loss=0.9479312896728516\n",
      "Training model 1\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T13:43:34.303300Z [\u001B[32minfo     ] Starting training              dataset=4312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T13:44:24.873464Z [\u001B[32minfo     ] Training complete              train_loss=0.9245396256446838\n",
      "Training model 2\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T13:44:24.888394Z [\u001B[32minfo     ] Starting training              dataset=4312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T13:45:15.469333Z [\u001B[32minfo     ] Training complete              train_loss=0.955090343952179\n",
      "Training model 3\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T13:45:15.482320Z [\u001B[32minfo     ] Starting training              dataset=4312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T13:46:06.060861Z [\u001B[32minfo     ] Training complete              train_loss=0.9402186870574951\n",
      "Training model 4\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:109] 2021-01-18T13:46:06.072062Z [\u001B[32minfo     ] Starting training              dataset=4312 epoch=10\n",
      "[15063-MainThread] [baal.modelwrapper:train_on_dataset:119] 2021-01-18T13:46:56.660140Z [\u001B[32minfo     ] Training complete              train_loss=0.9586511850357056\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:147] 2021-01-18T13:46:56.666844Z [\u001B[32minfo     ] Starting evaluating            dataset=10000\n",
      "[15063-MainThread] [baal.modelwrapper:test_on_dataset:156] 2021-01-18T13:47:12.289430Z [\u001B[32minfo     ] Evaluation complete            test_loss=0.5396298170089722\n",
      "[15063-MainThread] [baal.modelwrapper:predict_on_dataset_generator:239] 2021-01-18T13:47:12.299882Z [\u001B[32minfo     ] Start Predict                  dataset=45688\n",
      " 28%|██▊       | 12755/45688 [07:24<18:57, 28.95it/s]"
     ]
    }
   ],
   "source": [
    "labelling_progress = active_set._labelled.copy().astype(np.uint16)\n",
    "report = []\n",
    "for epoch in tqdm(range(hyperparams.epoch)):\n",
    "    model.clear_checkpoints()\n",
    "    # Load the initial weights.\n",
    "    for model_iter in range(hyperparams.iterations):\n",
    "        print(f\"Training model {model_iter}\")\n",
    "        model.load_state_dict(init_weights)\n",
    "        model.model.apply(weights_reset)\n",
    "        _ = model.train_on_dataset(active_set, optimizer=optimizer, batch_size=hyperparams.batch_size,\n",
    "                                 use_cuda=use_cuda, epoch=hyperparams.training_duration)\n",
    "        model.add_checkpoint()\n",
    "    \n",
    "    \n",
    "\n",
    "    # Get test NLL!\n",
    "    model.test_on_dataset(test_set, hyperparams.batch_size, use_cuda,\n",
    "                          average_predictions=hyperparams.iterations)\n",
    "    metrics = model.metrics\n",
    "\n",
    "    # We can now label the most uncertain samples according to our heuristic.\n",
    "    should_continue = active_loop.step()\n",
    "    # Keep track of progress\n",
    "    labelling_progress += active_set._labelled.astype(np.uint16)\n",
    "    if not should_continue:\n",
    "            break\n",
    "\n",
    "    test_loss = metrics['test_loss'].value\n",
    "    logs = {\n",
    "        \"test_nll\": test_loss,\n",
    "        \"epoch\": epoch,\n",
    "        \"Next Training set size\": len(active_set)\n",
    "    }\n",
    "    report.append(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb5642da0d0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [v['test_nll'] for v in report]\n",
    "y = [v['Next Training set size'] for v in report]\n",
    "plt.plot(y, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}