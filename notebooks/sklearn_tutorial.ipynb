{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# How to use BaaL with Scikit-Learn models\n",
    "\n",
    "In this tutorial, you will learn how to use BaaL on a scikit-learn model.\n",
    "In this case, we will use `RandomForestClassifier`.\n",
    "\n",
    "This tutorial is based on the tutorial from [Saimadhu Polamuri](https://dataaspirant.com/2017/06/26/random-forest-classifier-python-scikit-learn/).\n",
    "\n",
    "First, if you have not done it yet, let's install BaaL.\n",
    "\n",
    "```bash\n",
    "pip install baal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:",
      "\n",
      "  %reload_ext",
      " ",
      "autoreload",
      "\n",
      "Train Accuracy :: ",
      " ",
      "1.0",
      "\n",
      "Test Accuracy  :: ",
      " ",
      "0.9658536585365853",
      "\n",
      " Confusion matrix ",
      " ",
      "[[119   3]\n [  4  79]]",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/fred/miniconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n  FutureWarning)\n",
      "/home/fred/miniconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "HEADERS = [\"CodeNumber\", \"ClumpThickness\", \"UniformityCellSize\", \"UniformityCellShape\", \"MarginalAdhesion\",\n",
    "           \"SingleEpithelialCellSize\", \"BareNuclei\", \"BlandChromatin\", \"NormalNucleoli\", \"Mitoses\", \"CancerType\"]\n",
    "\n",
    "import pandas as pd\n",
    "data = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "dataset = pd.read_csv(data)\n",
    "dataset.columns = HEADERS\n",
    "\n",
    "# Handle missing labels\n",
    "dataset = dataset[dataset[HEADERS[6]] != '?']\n",
    "\n",
    "\n",
    "# Split\n",
    "train_x, test_x, train_y, test_y = train_test_split(dataset[HEADERS[1:-1]], dataset[HEADERS[-1]],\n",
    "                                                        train_size=0.7)\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "# Get metrics\n",
    "predictions = clf.predict(test_x)\n",
    "print(\"Train Accuracy :: \", accuracy_score(train_y, clf.predict(train_x)))\n",
    "print(\"Test Accuracy  :: \", accuracy_score(test_y, predictions))\n",
    "print(\" Confusion matrix \", confusion_matrix(test_y, predictions))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that you have a trained model, you can use it to perform uncertainty estimation.\n",
    "The SKLearn API directly propose `RandomForestClassifier.predict_proba` which would return the mean\n",
    "response from the RandomForest.\n",
    "\n",
    "But if you wish to try one of our heuristics in `baal.active.heuristics`, here's how."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Using 10 estimators",
      "\n",
      "Uncertainty per sample",
      "\n",
      "[0.         0.         0.         0.         0.         0.\n 0.32508297 0.         0.         0.32508297 0.         0.32508297\n 0.         0.         0.         0.         0.32508297 0.\n 0.         0.         0.         0.         0.         0.50040242\n 0.         0.         0.32508297 0.         0.32508297 0.\n 0.         0.         0.32508297 0.         0.         0.32508297\n 0.         0.         0.         0.         0.         0.\n 0.         0.50040242 0.         0.69314718 0.         0.\n 0.         0.32508297 0.         0.6108643  0.         0.32508297\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.32508297 0.         0.         0.\n 0.         0.32508297 0.         0.         0.         0.50040242\n 0.         0.6108643  0.         0.         0.         0.\n 0.         0.32508297 0.         0.         0.         0.\n 0.         0.50040242 0.6108643  0.         0.         0.50040242\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.69314718 0.         0.         0.67301167 0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.32508297 0.         0.32508297 0.50040242 0.50040242\n 0.         0.         0.         0.         0.         0.67301167\n 0.         0.         0.         0.         0.         0.6108643\n 0.         0.32508297 0.         0.         0.         0.32508297\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.6108643  0.         0.         0.\n 0.         0.         0.         0.67301167 0.         0.\n 0.         0.         0.         0.         0.         0.6108643\n 0.32508297 0.         0.         0.         0.         0.\n 0.         0.32508297 0.         0.         0.32508297 0.\n 0.         0.         0.         0.         0.         0.32508297\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.6108643  0.32508297 0.67301167 0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.        ]",
      "\n",
      "Ranks",
      "\n",
      "[102  45 105 125 153 190 146  73 161 188  51 131  86  89  23 118 119  71\n  43  85  67  53  35  62 162 172  32 117 115 133 169  49  28  26  79   6\n   9  11 189  16 137 179  77  70  58  90  88  59  87  72  84  60  74  61\n  83  63  78  82  64  75  57  65  66  80  68  69  76  81  46  56  13  22\n  21  20  19  18  17  15  14  12  25  10   8   7   5   4   3   2   1  24\n  27  55  41  54  52  50  48  47  92  44  42  40  29  39  38  37  36  34\n  33  31  30  91 204  93 164 175 174 173 171 170 168 167 166 165 163  94\n 160 159 158 157 156 155 154 152 151 176 177 178 180 202 201 200 199 198\n 197 196 195 194 193 192 191 187 186 185 184 183 182 181 150 149 148 120\n 114 113 112 111 110 109 108 107 106 104 103 203 101 100  99  98  97  96\n  95 116 121 147 122 145 144 143 142 141 140 139 138 136 135 134 132 130\n 129 128 127 126 124 123   0]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from baal.active.heuristics import BALD\n",
    "print(f\"Using {len(clf.estimators_)} estimators\")\n",
    "\n",
    "# Predict independently for all estimators.\n",
    "x = np.array(list(map(lambda e: e.predict_proba(test_x), clf.estimators_)))\n",
    "# Roll axis because BaaL expect [n_samples, n_classes, ..., n_estimations]\n",
    "x = np.rollaxis(x, 0, 3)\n",
    "print(\"Uncertainty per sample\")\n",
    "print(BALD().compute_score(x))\n",
    "\n",
    "print(\"Ranks\")\n",
    "print(BALD()(x))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Active learning with SkLearn\n",
    "\n",
    "You can also try Active learning by using `ActiveNumpyArray`.\n",
    "\n",
    "\n",
    "**NOTE**: Because we focus on images, we have not made experiments on this setup."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Dataset size",
      " ",
      "10",
      "\n",
      "Test Accuracy  :: ",
      " ",
      "0.9219512195121952",
      "\n",
      "Dataset size",
      " ",
      "20",
      "\n",
      "Test Accuracy  :: ",
      " ",
      "0.9658536585365853",
      "\n",
      "Dataset size",
      " ",
      "30",
      "\n",
      "Test Accuracy  :: ",
      " ",
      "0.9414634146341463",
      "\n",
      "Dataset size",
      " ",
      "40",
      "\n",
      "Test Accuracy  :: ",
      " ",
      "0.9512195121951219",
      "\n",
      "Dataset size",
      " ",
      "50",
      "\n",
      "Test Accuracy  :: ",
      " ",
      "0.9609756097560975",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/fred/miniconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from baal.active.dataset import ActiveNumpyArray\n",
    "dataset = ActiveNumpyArray((train_x, train_y))\n",
    "\n",
    "# We start with a 10 labelled samples.\n",
    "dataset.label_randomly(10)\n",
    "\n",
    "heuristic = BALD()\n",
    "\n",
    "# We will use a RandomForest in this case.\n",
    "clf = RandomForestClassifier()\n",
    "def predict(test, clf):\n",
    "    # Predict with all fitted estimators.\n",
    "    x = np.array(list(map(lambda e: e.predict_proba(test[0]), clf.estimators_)))\n",
    "    \n",
    "    # Roll axis because BaaL expect [n_samples, n_classes, ..., n_estimations]\n",
    "    x = np.rollaxis(x, 0, 3)\n",
    "    return x\n",
    "\n",
    "for _ in range(5):\n",
    "  print(\"Dataset size\", len(dataset))\n",
    "  clf.fit(*dataset.dataset)\n",
    "  predictions = clf.predict(test_x)\n",
    "  print(\"Test Accuracy  :: \", accuracy_score(test_y, predictions))\n",
    "  probs = predict(dataset.pool, clf)\n",
    "  to_label = heuristic(probs)\n",
    "  ndata_to_label = 10\n",
    "  if len(to_label) > 0:\n",
    "      dataset.label(to_label[: ndata_to_label])\n",
    "  else:\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-a12da823",
   "language": "python",
   "display_name": "PyCharm (bayesian-active-learning)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}